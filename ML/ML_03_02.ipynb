{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.16.4', '0.24.2')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import re\n",
    "%reload_ext version_information\n",
    "np.__version__, pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2a) Einlesen und Entpacken des tar.gz Files mit tarfile</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open(\"20news-18828.tar.gz\")\n",
    "#tar.extractall() #gefährlich, entpackt direkt alles\n",
    "#tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2b) Speichern der Beiträge der Newsgroups <I>alt.atheism, comp.graphics, sci.space </I>\n",
    "    und <I>talk.religion.misc</I> als Strings in ein Array</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20news-18828 is 0 bytes in size and is a directory.\n",
      "20news-18828/alt.atheism is 0 bytes in size and is a directory.\n",
      "20news-18828/alt.atheism/51203 is 1372 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/51277 is 1514 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/53192 is 1752 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/53222 is 1991 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/51283 is 2615 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/53759 is 577 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/53225 is 753 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/53098 is 1200 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/51275 is 2386 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/53601 is 892 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/54173 is 1587 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/53334 is 1045 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/51158 is 530 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/53803 is 1423 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/51211 is 10233 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/51315 is 1036 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/53179 is 1500 bytes in size and is a regular file.\n",
      "20news-18828/alt.atheism/53657 is 1142 bytes in size and is a regular file.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for tarinfo in tar:\n",
    "    print(tarinfo.name, \"is\", tarinfo.size, \"bytes in size and is \", end=\"\")\n",
    "    if tarinfo.isreg():\n",
    "        print(\"a regular file.\")\n",
    "    elif tarinfo.isdir():\n",
    "        print(\"a directory.\")\n",
    "    else:\n",
    "        print(\"something else.\")\n",
    "        \n",
    "    i+=1\n",
    "    if i == 20:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "groups = [\"20news-18828/alt.atheism\", \"20news-18828/comp.graphics\", \"20news-18828/sci.space\", \"20news-18828/talk.religion.misc\"]\n",
    "data = []\n",
    "needed = False\n",
    "for tarinfo in tar:\n",
    "    if tarinfo.isdir() and tarinfo.name in groups:\n",
    "        needed = True\n",
    "    elif tarinfo.isreg() and needed:\n",
    "        data.append(open(tarinfo.name).read())\n",
    "    elif tarinfo.isdir() and tarinfo.name not in groups:\n",
    "        needed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kontrolle: Es müssten jetzt 3387 Strings\n",
    "im Speicher sein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3387,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar.close()\n",
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entfernen der ersten zwei Zeilen, also dem Newsgroup-Header, aus den Dateien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_header(text):\n",
    "    _before, _blankline, after = text.partition ('\\n\\n')\n",
    "    return after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [strip_header(text) for text in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2c) Aufteilen der Strings in Worte(Token) und speichern der verschiedenen Worte über alle Texte</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = []\n",
    "# all_words = []\n",
    "\n",
    "# for txtline in data:\n",
    "#     l = re.compile(r\"(?u)\\b\\w\\w+\\b\").findall(txtline.lower())\n",
    "#     words.append(l)\n",
    "#     all_words = all_words + l\n",
    "    \n",
    "# unique_set = set(all_words)\n",
    "# unique_list = list(unique_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kontrolle: Es sollten 41777 verschiedene Worte vorhanden sein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnen eines Merkmalsvektors für jeden Text, der für jedes Wort des Vokabulars seine Häufigkeit innerhalb des Texts\n",
    "enthält."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3387, 41777)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "x_train_tf = count_vect.fit_transform(data)\n",
    "x_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dauert extrem lange, 15 min, TODO: andere Lösung?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merk = np.zeros((np.shape(unique_list)[0], np.shape(data)[0]))\n",
    "# i = 0\n",
    "# for l in words:\n",
    "#     for w in l:\n",
    "#         merk[unique_list.index(w)][i] += 1\n",
    "#     i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(merk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(merk[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>d. Verwenden Sie die ersten 60% der Daten als Trainingsdatensatz, die restlichen als Testdatensatz. Trainieren Sie damit einen multinomialen naiven Bayes-Klassifikator. Bestimmen\n",
    "Sie den Anteil korrekter Klassifikationen auf Ihren Trainings- und Testdaten. Wie gut\n",
    "generalisiert Ihr Klassifikator?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2032, 41777), (1355, 41777))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "traindata, testdata = train_test_split(x_train_tf, train_size = 0.6)\n",
    "\n",
    "traindata.shape, testdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# x_train_tfidf = tfidf_transformer.fit_transform(x_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# clf = MultinomialNB().fit(x_train_tf, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_tf = count_vect.transform(data)\n",
    "# x_test_tfidf = tfidf_transformer.transform(x_test_tf)\n",
    "# predicted = clf.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# print(\"Accuracy:\", accuracy_score(data, predicted))\n",
    "# print(metrics.classification_report(data, predicted, data),metrics.confusion_matrix(data, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.7.3 64bit [MSC v.1915 64 bit (AMD64)]"
        },
        {
         "module": "IPython",
         "version": "7.6.1"
        },
        {
         "module": "OS",
         "version": "Windows 10 10.0.18362 SP0"
        },
        {
         "module": "numpy",
         "version": "1.16.4"
        },
        {
         "module": "pandas",
         "version": "0.24.2"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.7.3 64bit [MSC v.1915 64 bit (AMD64)]</td></tr><tr><td>IPython</td><td>7.6.1</td></tr><tr><td>OS</td><td>Windows 10 10.0.18362 SP0</td></tr><tr><td>numpy</td><td>1.16.4</td></tr><tr><td>pandas</td><td>0.24.2</td></tr><tr><td colspan='2'>Mon Nov 18 09:39:12 2019 Mitteleuropäische Zeit</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.7.3 64bit [MSC v.1915 64 bit (AMD64)] \\\\ \\hline\n",
       "IPython & 7.6.1 \\\\ \\hline\n",
       "OS & Windows 10 10.0.18362 SP0 \\\\ \\hline\n",
       "numpy & 1.16.4 \\\\ \\hline\n",
       "pandas & 0.24.2 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Mon Nov 18 09:39:12 2019 Mitteleuropäische Zeit} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.7.3 64bit [MSC v.1915 64 bit (AMD64)]\n",
       "IPython 7.6.1\n",
       "OS Windows 10 10.0.18362 SP0\n",
       "numpy 1.16.4\n",
       "pandas 0.24.2\n",
       "Mon Nov 18 09:39:12 2019 Mitteleuropäische Zeit"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%version_information numpy, pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
